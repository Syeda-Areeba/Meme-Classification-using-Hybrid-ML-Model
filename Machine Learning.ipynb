{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5f274b",
   "metadata": {},
   "source": [
    "# Name : Syeda Areeba Nadeem\n",
    "# Roll No.: 21I-0307\n",
    "# Section: BS(AI)-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32d6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "from skimage import filters\n",
    "from skimage import feature\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# from PIL import Image\n",
    "# from pytesseract import pytesseract\n",
    "# !pip install pytesseract\n",
    "# !pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1985613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6992 entries, 0 to 6991\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0         6992 non-null   int64 \n",
      " 1   image_name         6992 non-null   object\n",
      " 2   text_ocr           6831 non-null   object\n",
      " 3   text_corrected     6987 non-null   object\n",
      " 4   overall_sentiment  6992 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 273.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_name           0\n",
       "text_corrected       0\n",
       "overall_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv('labels.csv')\n",
    "DF.info()\n",
    "DF\n",
    "\n",
    "DF.fillna(0,inplace = True)\n",
    "df = DF[['image_name','text_corrected','overall_sentiment']]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe22dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHALLENGE ACCEPTED! Friend: You can't honestly watch How I Met Your Mother again for like the 4th time...\" Me:\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "temp = df[df['text_corrected']== 0]\n",
    "\n",
    "for i in temp.index:\n",
    "    print(DF.iloc[i]['text_ocr'])\n",
    "    if(DF.iloc[i]['text_ocr']!=0):  #check if the ocr column does not has a null value\n",
    "        df.iloc[i]['text_corrected'] = DF.iloc[i]['text_ocr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d8145",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65eaa820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepocessing(string_text):\n",
    "  \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    \n",
    "    text = re.sub(r\"\\S+.com\",'', string_text)  # remove instances like imgflip.com\n",
    "    text = re.sub(r\"www.\\S+\",'', text)  # remove links www.facebook.com -> might not need this, above one can also do that\n",
    "    text = re.sub(r\"http\\S+\",'', text)  # remove urls \n",
    "\n",
    "    text = re.sub(\"(@[A-Za-z]+)|(#[A-Za-z]+)\",'', text)\n",
    "    text = re.sub(\"(@)|(#)\",'', text)  #to remove hashtags like this => #10 to this => 10\n",
    "    \n",
    "    x = [ch for ch in text if ch not in string.punctuation]\n",
    "    text = ''.join(x)\n",
    "    clean = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
    "    text =  ' '.join(clean)\n",
    "    \n",
    "    x = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text =  ''.join(x)\n",
    "    \n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f7c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look friend lightyear sohalikut trend play 10 ...</td>\n",
       "      <td>image_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best 10 yearchallenge completed less 4 years k...</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sam thorne follow follow saw everyone posting ...</td>\n",
       "      <td>image_3.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 year challenge sweet dee edition</td>\n",
       "      <td>image_4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 year challenge filter 47 hilarious 10 year ...</td>\n",
       "      <td>image_5.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>tuesday mardi gras wednesday valentines friday...</td>\n",
       "      <td>image_6988.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>must watch movies 2017 iti chennai memes maana...</td>\n",
       "      <td>image_6989.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>less talking planning soda junk food complaini...</td>\n",
       "      <td>image_6990.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>time fantasy one time unless make time</td>\n",
       "      <td>image_6991.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>starting point every good idea arhtistic</td>\n",
       "      <td>image_6992.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_corrected      image_name\n",
       "0     look friend lightyear sohalikut trend play 10 ...     image_1.jpg\n",
       "1     best 10 yearchallenge completed less 4 years k...    image_2.jpeg\n",
       "2     sam thorne follow follow saw everyone posting ...     image_3.JPG\n",
       "3                   10 year challenge sweet dee edition     image_4.png\n",
       "4     10 year challenge filter 47 hilarious 10 year ...     image_5.png\n",
       "...                                                 ...             ...\n",
       "6987  tuesday mardi gras wednesday valentines friday...  image_6988.jpg\n",
       "6988  must watch movies 2017 iti chennai memes maana...  image_6989.jpg\n",
       "6989  less talking planning soda junk food complaini...  image_6990.png\n",
       "6990             time fantasy one time unless make time  image_6991.jpg\n",
       "6991           starting point every good idea arhtistic  image_6992.jpg\n",
       "\n",
       "[6988 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['text_corrected']!=0]\n",
    "df_text = df[['text_corrected','image_name']]\n",
    "\n",
    "for i in range(len(df_text)):\n",
    "    row_string = df_text.iloc[i]['text_corrected']\n",
    "#     print(row_string)    \n",
    "    df_text.iloc[i]['text_corrected'] = text_prepocessing(row_string)\n",
    "\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5bf627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look friend lightyear sohalikut trend play 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best 10 yearchallenge completed less 4 years k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sam thorne follow follow saw everyone posting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 year challenge sweet dee edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 year challenge filter 47 hilarious 10 year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>tuesday mardi gras wednesday valentines friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>must watch movies 2017 iti chennai memes maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>less talking planning soda junk food complaini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>time fantasy one time unless make time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>starting point every good idea arhtistic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6988 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_corrected\n",
       "0     look friend lightyear sohalikut trend play 10 ...\n",
       "1     best 10 yearchallenge completed less 4 years k...\n",
       "2     sam thorne follow follow saw everyone posting ...\n",
       "3                   10 year challenge sweet dee edition\n",
       "4     10 year challenge filter 47 hilarious 10 year ...\n",
       "...                                                 ...\n",
       "6987  tuesday mardi gras wednesday valentines friday...\n",
       "6988  must watch movies 2017 iti chennai memes maana...\n",
       "6989  less talking planning soda junk food complaini...\n",
       "6990             time fantasy one time unless make time\n",
       "6991           starting point every good idea arhtistic\n",
       "\n",
       "[6988 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names = list(df_text['image_name'])\n",
    "df_text.drop('image_name',axis=1,inplace=True)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a862f124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look friend lightyear sohalikut trend play 10 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best 10 yearchallenge completed less 4 years k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sam thorne follow follow saw everyone posting ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 year challenge sweet dee edition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 year challenge filter 47 hilarious 10 year ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>tuesday mardi gras wednesday valentines friday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>must watch movies 2017 iti chennai memes maana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>less talking planning soda junk food complaini...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>time fantasy one time unless make time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>starting point every good idea arhtistic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_corrected  Sentiment\n",
       "0     look friend lightyear sohalikut trend play 10 ...          1\n",
       "1     best 10 yearchallenge completed less 4 years k...          1\n",
       "2     sam thorne follow follow saw everyone posting ...          1\n",
       "3                   10 year challenge sweet dee edition          1\n",
       "4     10 year challenge filter 47 hilarious 10 year ...          0\n",
       "...                                                 ...        ...\n",
       "6987  tuesday mardi gras wednesday valentines friday...          0\n",
       "6988  must watch movies 2017 iti chennai memes maana...          0\n",
       "6989  less talking planning soda junk food complaini...          1\n",
       "6990             time fantasy one time unless make time          1\n",
       "6991           starting point every good idea arhtistic          1\n",
       "\n",
       "[6988 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['Sentiment'] = df['overall_sentiment']\n",
    "order = {'very_positive':1,'positive':1,'neutral':0,'negative':-1,'very_negative':-1}\n",
    "df_text['Sentiment'] = df_text['Sentiment'].map(order)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc1a83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_text['text_corrected'],df_text['Sentiment'], test_size=0.24,\n",
    "                                                    random_state=31)\n",
    "\n",
    "train = pd.concat([X_train,y_train],axis=1).reset_index()\n",
    "test = pd.concat([X_test,y_test],axis=1).reset_index()\n",
    "\n",
    "train.drop(['index'],axis=1,inplace=True)\n",
    "test.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "train.to_csv('Train.csv',index=False)\n",
    "test.to_csv('Test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f3002",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4791cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  with open('CV_vectorizer.pkl','wb') as f:\n",
    "#     pickle.dump(CountVectorizer(),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6243f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 54.00572246065808\n",
      "Recall:  34.08476634592865\n",
      "Precision:  31.735708698497838\n",
      "F1 score:  31.93791628822283\n",
      "Confusion Matrix: \n",
      "[[  0  26 102]\n",
      " [  3 102 344]\n",
      " [ 11 157 653]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "X = df_text['text_corrected']\n",
    "y = df_text['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31)\n",
    "\n",
    "pipeline = Pipeline(steps=[('count_vec', TfidfVectorizer()), ('scaler', MaxAbsScaler())\n",
    "                          ,('model', LogisticRegression())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55aa7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_text['text_corrected']\n",
    "y = df_text['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31)\n",
    "\n",
    "CV_vectorizer = CountVectorizer()\n",
    "X_train_CV = CV_vectorizer.fit_transform(X_train)\n",
    "X_test_CV = CV_vectorizer.transform(X_test)\n",
    "# print(CV_vectorizer.vocabulary_)\n",
    "X_train_CV.toarray().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_CV_model = svm.SVC(kernel='linear',C=2)\n",
    "SVM_CV_model.fit(X_train_CV,y_train)\n",
    "y_pred = SVM_CV_model.predict(X_test_CV)\n",
    "\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "SVM_CV_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b689d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_CV_model = LogisticRegression(C=8.2,random_state=0).fit(X_train_CV, y_train)\n",
    "y_pred = LR_CV_model.predict(X_test_CV)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ', f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "LR_CV_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8edcc8",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a6b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  51.716738197424895\n",
      "Recall:  34.808498178385314\n",
      "Precision:  34.61306425104154\n",
      "F1 score:  34.18165931264592\n",
      "Confusion Matrix: \n",
      "[[  4  35  89]\n",
      " [ 16 136 297]\n",
      " [ 34 204 583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.07      0.03      0.04       128\n",
      "     Neutral       0.36      0.30      0.33       449\n",
      "    Negative       0.60      0.71      0.65       821\n",
      "\n",
      "    accuracy                           0.52      1398\n",
      "   macro avg       0.35      0.35      0.34      1398\n",
      "weighted avg       0.48      0.52      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ETC_CV_model = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "ETC_CV_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ETC_CV_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "ETC_CV_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd85c6",
   "metadata": {},
   "source": [
    "# Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "843ff851",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_text['text_corrected']\n",
    "y = df_text['Sentiment']\n",
    "\n",
    "TFIDF_vectorizer = TfidfVectorizer(max_df=0.75)\n",
    "X = TFIDF_vectorizer.fit_transform(X)\n",
    "X.toarray().shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf68e1",
   "metadata": {},
   "source": [
    "## LR - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8132f405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  51.072961373390555\n",
      "F1 score:  35.033008150222294\n",
      "Recall:  35.270728242352064\n",
      "Precision:  35.99649408067987\n",
      "Confusion Matrix: \n",
      "[[  7  28  93]\n",
      " [  8 141 300]\n",
      " [ 44 211 566]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.12      0.05      0.07       128\n",
      "     Neutral       0.37      0.31      0.34       449\n",
      "    Negative       0.59      0.69      0.64       821\n",
      "\n",
      "    accuracy                           0.51      1398\n",
      "   macro avg       0.36      0.35      0.35      1398\n",
      "weighted avg       0.48      0.51      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_TFIDF_model = LogisticRegression(C=131.2,random_state=0).fit(X_train, y_train)\n",
    "y_pred = LR_TFIDF_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ', f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "LR_TFIDF_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1c5bf",
   "metadata": {},
   "source": [
    "## SVM - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65e71579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 51.28755364806867\n",
      "Recall:  35.83449798103242\n",
      "Precision:  36.92640308246058\n",
      "Confusion Matrix: \n",
      "[[ 11  30  87]\n",
      " [ 12 128 309]\n",
      " [ 51 192 578]]\n",
      "F1 score:  35.77741779253909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.15      0.09      0.11       128\n",
      "     Neutral       0.37      0.29      0.32       449\n",
      "    Negative       0.59      0.70      0.64       821\n",
      "\n",
      "    accuracy                           0.51      1398\n",
      "   macro avg       0.37      0.36      0.36      1398\n",
      "weighted avg       0.48      0.51      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_TFIDF_model = svm.SVC(kernel='linear',C=5)\n",
    "SVM_TFIDF_model.fit(X_train,y_train)\n",
    "y_pred = SVM_TFIDF_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "SVM_TFIDF_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27d5fd",
   "metadata": {},
   "source": [
    "## ETC-TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45dd28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 53.71959942775394\n",
      "Recall:  34.71636271947315\n",
      "Precision:  34.97180840057935\n",
      "Confusion Matrix: \n",
      "[[  3  29  96]\n",
      " [  7 106 336]\n",
      " [ 26 153 642]]\n",
      "F1 score:  33.39368570273382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.08      0.02      0.04       128\n",
      "     Neutral       0.37      0.24      0.29       449\n",
      "    Negative       0.60      0.78      0.68       821\n",
      "\n",
      "    accuracy                           0.54      1398\n",
      "   macro avg       0.35      0.35      0.33      1398\n",
      "weighted avg       0.48      0.54      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ETC_TFIDF_model = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "ETC_TFIDF_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ETC_TFIDF_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "ETC_TFIDF_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75063ff2",
   "metadata": {},
   "source": [
    "# Majority voting for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b9a3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  53.71959942775394\n",
      "Recall:  34.71636271947315\n",
      "Precision:  34.97180840057935\n",
      "Confusion Matrix: \n",
      "[[  3  29  96]\n",
      " [  7 106 336]\n",
      " [ 26 153 642]]\n",
      "F1 score:  35.255242201339975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.14      0.06      0.09       128\n",
      "     Neutral       0.37      0.28      0.32       449\n",
      "    Negative       0.59      0.73      0.65       821\n",
      "\n",
      "    accuracy                           0.52      1398\n",
      "   macro avg       0.37      0.36      0.35      1398\n",
      "weighted avg       0.48      0.52      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = LR_TFIDF_model\n",
    "model_2 = SVM_TFIDF_model\n",
    "model_3 = ETC_TFIDF_model\n",
    "\n",
    "final_model = VotingClassifier(estimators=[('lr_tfidf', model_1), ('svm_tfidf', model_2), ('etc_tfidf', model_3)], voting='hard')\n",
    "final_model.fit(X_train, y_train)\n",
    "pred_final = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, pred_final, average='macro')*100)\n",
    "f1_text =f1_score(y_test, pred_final, average='macro')*100\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,pred_final,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c1b161",
   "metadata": {},
   "source": [
    "# Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e42ca27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_text['text_corrected']\n",
    "y = df_text['Sentiment']\n",
    "\n",
    "H_vectorizer = HashingVectorizer()\n",
    "X = H_vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03007329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 51.430615164520745\n",
      "Recall:  35.460416898381126\n",
      "Precision:  36.99867161626087\n",
      "F1 score:  35.31623675391313\n",
      "Confusion Matrix: \n",
      "[[ 10  29  89]\n",
      " [ 11 121 317]\n",
      " [ 39 194 588]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.17      0.08      0.11       128\n",
      "     Neutral       0.35      0.27      0.31       449\n",
      "    Negative       0.59      0.72      0.65       821\n",
      "\n",
      "    accuracy                           0.51      1398\n",
      "   macro avg       0.37      0.35      0.35      1398\n",
      "weighted avg       0.48      0.51      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_HV_model = svm.SVC(kernel='linear',C=5)\n",
    "SVM_HV_model.fit(X_train,y_train)\n",
    "y_pred = SVM_HV_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "SVM_HV_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41056ebe",
   "metadata": {},
   "source": [
    "## LR - Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ccb69d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  50.35765379113018\n",
      "Recall:  35.25272586620514\n",
      "Precision:  35.80417154442039\n",
      "Confusion Matrix: \n",
      "[[  8  26  94]\n",
      " [ 14 146 289]\n",
      " [ 47 224 550]]\n",
      "F1 score:  35.130612488088914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.12      0.06      0.08       128\n",
      "     Neutral       0.37      0.33      0.35       449\n",
      "    Negative       0.59      0.67      0.63       821\n",
      "\n",
      "    accuracy                           0.50      1398\n",
      "   macro avg       0.36      0.35      0.35      1398\n",
      "weighted avg       0.48      0.50      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_HV_model = LogisticRegression(C=131.2,random_state=0).fit(X_train, y_train)\n",
    "y_pred = LR_HV_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "LR_HV_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba2f7f",
   "metadata": {},
   "source": [
    "# IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92891f",
   "metadata": {},
   "source": [
    "The following commented code is for reading images from folder in batches (1000 at a time) extracting thier features and storing them in a dataframe. Later those dataframes are used for ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23fcc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_img = pd.read_csv(\"labels.csv\",index_col=0)\n",
    "# df_img = DF_img[['image_name','overall_sentiment']]\n",
    "# df_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4aa9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def canny_feature_extraction(image_path):\n",
    "#     Image = imread(image_path,as_gray=True)\n",
    "#     image_resized = resize(Image, (50,50))\n",
    "#     Canny_img = feature.canny(image_resized)\n",
    "#     image_features = np.reshape(Canny_img,50*50).astype(int)\n",
    "#     return image_features\n",
    "\n",
    "# def sobel_feature_extraction(image_path):\n",
    "#     Image = imread(image_path,as_gray=True)\n",
    "#     image_resized = resize(Image, (50,50))\n",
    "#     Sobel_img = filters.sobel(image_resized)\n",
    "#     image_features = np.reshape(Sobel_img,50*50)\n",
    "#     return image_features\n",
    "\n",
    "# def pixel_feature_extraction(image_path):\n",
    "#     Image = imread(image_path,as_gray=True)\n",
    "#     image_resized = resize(Image, (50,50))\n",
    "#     image_features = np.reshape(image_resized,(50*50))\n",
    "#     return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d8adec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './images-6/'\n",
    "\n",
    "# img_name=[]\n",
    "# img_sentiments=[]\n",
    "\n",
    "# df_px = pd.DataFrame(columns=[x for x in range(0,2500)])\n",
    "# df_sb = pd.DataFrame(columns=[x for x in range(0,2500)])\n",
    "# df_can = pd.DataFrame(columns=[x for x in range(0,2500)])\n",
    "\n",
    "# images = os.listdir(path)\n",
    "# for img in images:\n",
    "    \n",
    "#     canny = canny_feature_extraction(path+img)\n",
    "#     sobel = sobel_feature_extraction(path+img)\n",
    "#     pixel = pixel_feature_extraction(path+img)\n",
    "    \n",
    "#     df_px.loc[len(df_px.index)] = pixel\n",
    "#     df_sb.loc[len(df_sb.index)] = sobel\n",
    "#     df_can.loc[len(df_can.index)] = canny\n",
    "    \n",
    "#     img_name.append(img) \n",
    "    \n",
    "# #     print(img,\"  completed\")\n",
    "#     sentiment = df[df['image_name']==img]['overall_sentiment']\n",
    "#     img_sentiments.append(sentiment.values[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8069f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_can.insert(loc=0, column='Name', value=img_name, allow_duplicates = False)\n",
    "# df_can.insert(loc=1, column='Sentiment', value=img_sentiments, allow_duplicates = False)\n",
    "\n",
    "# df_sb.insert(loc=0, column='Name', value=img_name, allow_duplicates = False)\n",
    "# df_sb.insert(loc=1, column='Sentiment', value=img_sentiments, allow_duplicates = False)\n",
    "\n",
    "# df_px.insert(loc=0, column='Name', value=img_name, allow_duplicates = False)\n",
    "# df_px.insert(loc=1, column='Sentiment', value=img_sentiments, allow_duplicates = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "654de0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_px.to_csv(\"pixel-6.csv\",index=False)\n",
    "# df_sb.to_csv(\"sobel-6.csv\",index=False)\n",
    "# df_can.to_csv(\"canny-6.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "355d63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = {'very_positive':1,'positive':1,'neutral':0,'negative':-1,'very_negative':-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b91cee",
   "metadata": {},
   "source": [
    "# Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8775e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf0 = pd.read_csv(\"pixel-0.csv\")\n",
    "pdf1 = pd.read_csv(\"pixel-1.csv\")\n",
    "pdf2 = pd.read_csv(\"pixel-2.csv\")\n",
    "pdf3 = pd.read_csv(\"pixel-3.csv\")\n",
    "pdf4 = pd.read_csv(\"pixel-4.csv\")\n",
    "pdf5 = pd.read_csv(\"pixel-5.csv\")\n",
    "pdf6 = pd.read_csv(\"pixel-6.csv\")\n",
    "\n",
    "df_pixel = pd.concat([pdf0,pdf1,pdf2,pdf3,pdf4,pdf5,pdf6],axis=0)\n",
    "\n",
    "img_names = df_pixel['Name']\n",
    "df_pixel.drop(labels=['Name'],inplace=True,axis=1)\n",
    "\n",
    "df_pixel['Sentiment'] = df_pixel['Sentiment'].map(order)\n",
    "\n",
    "# df_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a9e9aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pixel.drop(labels=['Sentiment'],axis=1)\n",
    "Y = df_pixel[['Sentiment']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadaef5",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "063ca00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  48.24874910650465\n",
      "Recall:  35.110657821816886\n",
      "Precision:  35.21331863014314\n",
      "F1 score:  35.0756312332985\n",
      "Confusion Matrix: \n",
      "[[ 13  44  87]\n",
      " [ 46 144 254]\n",
      " [ 50 243 518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.12      0.09      0.10       144\n",
      "     Neutral       0.33      0.32      0.33       444\n",
      "    Negative       0.60      0.64      0.62       811\n",
      "\n",
      "    accuracy                           0.48      1399\n",
      "   macro avg       0.35      0.35      0.35      1399\n",
      "weighted avg       0.47      0.48      0.47      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD_PX_model = make_pipeline(StandardScaler(),SGDClassifier())\n",
    "\n",
    "SGD_PX_model.fit(X_train, y_train)\n",
    "y_pred = SGD_PX_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred, target_names=target_names))\n",
    "SGD_PX_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e070822",
   "metadata": {},
   "source": [
    "## MNB - Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4e53b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  44.603288062902074\n",
      "Recall:  33.979841432060915\n",
      "Precision:  34.1412936761774\n",
      "F1 score:  34.0077520183936\n",
      "Confusion Matrix: \n",
      "[[ 17  53  74]\n",
      " [ 51 150 243]\n",
      " [ 62 292 457]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.13      0.12      0.12       144\n",
      "     Neutral       0.30      0.34      0.32       444\n",
      "    Negative       0.59      0.56      0.58       811\n",
      "\n",
      "    accuracy                           0.45      1399\n",
      "   macro avg       0.34      0.34      0.34      1399\n",
      "weighted avg       0.45      0.45      0.45      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB_PX_model = MultinomialNB(alpha=16)\n",
    "MNB_PX_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = MNB_PX_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred, target_names=target_names))\n",
    "MNB_PX_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1960408",
   "metadata": {},
   "source": [
    "## KNN - Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a1329e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  47.46247319513939\n",
      "Recall:  33.85086689648958\n",
      "Precision:  33.442977355237936\n",
      "F1 score:  33.04597995010769\n",
      "Confusion Matrix: \n",
      "[[ 20  32  92]\n",
      " [ 54  81 309]\n",
      " [ 85 163 563]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.13      0.14      0.13       144\n",
      "     Neutral       0.29      0.18      0.23       444\n",
      "    Negative       0.58      0.69      0.63       811\n",
      "\n",
      "    accuracy                           0.47      1399\n",
      "   macro avg       0.33      0.34      0.33      1399\n",
      "weighted avg       0.44      0.47      0.45      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KNN_PX_model = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN_PX_model.fit(X_train, y_train)\n",
    "y_pred = KNN_PX_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "\n",
    "KNN_PX_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6471253",
   "metadata": {},
   "source": [
    "# SOBEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "60149d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = pd.read_csv(\"sobel-0.csv\")\n",
    "s1 = pd.read_csv(\"sobel-1.csv\")\n",
    "s2 = pd.read_csv(\"sobel-2.csv\")\n",
    "s3 = pd.read_csv(\"sobel-3.csv\")\n",
    "s4 = pd.read_csv(\"sobel-4.csv\")\n",
    "s5 = pd.read_csv(\"sobel-5.csv\")\n",
    "s6 = pd.read_csv(\"sobel-6.csv\")\n",
    "\n",
    "df_sobel = pd.concat([s0,s1,s2,s3,s4,s5,s6],axis=0)\n",
    "\n",
    "df_sobel.drop(labels=['Name'],inplace=True,axis=1)\n",
    "df_sobel['Sentiment'] = df_sobel['Sentiment'].map(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "37ad5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sobel.drop(labels=['Sentiment'],axis=1)\n",
    "Y = df_sobel[['Sentiment']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692e90a",
   "metadata": {},
   "source": [
    "## KNN - Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5cf200e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  48.67762687634024\n",
      "Recall:  34.50856837108378\n",
      "Precision:  34.48719782294646\n",
      "F1 score:  33.88910018935066\n",
      "Confusion Matrix: \n",
      "[[ 18  29  97]\n",
      " [ 53  91 300]\n",
      " [ 77 162 572]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.12      0.12      0.12       144\n",
      "     Neutral       0.32      0.20      0.25       444\n",
      "    Negative       0.59      0.71      0.64       811\n",
      "\n",
      "    accuracy                           0.49      1399\n",
      "   macro avg       0.34      0.35      0.34      1399\n",
      "weighted avg       0.46      0.49      0.46      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KNN_SB_model = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN_SB_model.fit(X_train, y_train)\n",
    "y_pred = KNN_SB_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "KNN_SB_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f188464",
   "metadata": {},
   "source": [
    "## MNB - sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "39a2e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  49.2494639027877\n",
      "Recall:  32.24000819561855\n",
      "Precision:  32.06874540111927\n",
      "F1 score:  30.895103396549878\n",
      "Confusion Matrix: \n",
      "[[  4  33 107]\n",
      " [ 11  93 340]\n",
      " [ 24 195 592]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.10      0.03      0.04       144\n",
      "     Neutral       0.29      0.21      0.24       444\n",
      "    Negative       0.57      0.73      0.64       811\n",
      "\n",
      "    accuracy                           0.49      1399\n",
      "   macro avg       0.32      0.32      0.31      1399\n",
      "weighted avg       0.43      0.49      0.45      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB_SB_model = MultinomialNB()\n",
    "MNB_SB_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = MNB_SB_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "\n",
    "MNB_CN_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c69f0",
   "metadata": {},
   "source": [
    "## LDA - Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "23e6a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  44.38884917798428\n",
      "Recall:  34.59113398231771\n",
      "Precision:  34.41022543647757\n",
      "F1 score:  34.408131459138694\n",
      "Confusion Matrix: \n",
      "[[ 23  42  79]\n",
      " [ 67 138 239]\n",
      " [ 98 253 460]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.12      0.16      0.14       144\n",
      "     Neutral       0.32      0.31      0.31       444\n",
      "    Negative       0.59      0.57      0.58       811\n",
      "\n",
      "    accuracy                           0.44      1399\n",
      "   macro avg       0.34      0.35      0.34      1399\n",
      "weighted avg       0.46      0.44      0.45      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LDA_SB_model = LinearDiscriminantAnalysis()\n",
    "LDA_SB_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LDA_SB_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "LDA_SB_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b764c",
   "metadata": {},
   "source": [
    "# CANNY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9ad44b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = pd.read_csv(\"canny-0.csv\")\n",
    "c1 = pd.read_csv(\"canny-1.csv\")\n",
    "c2 = pd.read_csv(\"canny-2.csv\")\n",
    "c3 = pd.read_csv(\"canny-3.csv\")\n",
    "c4 = pd.read_csv(\"canny-4.csv\")\n",
    "c5 = pd.read_csv(\"canny-5.csv\")\n",
    "c6 = pd.read_csv(\"canny-6.csv\")\n",
    "\n",
    "df_canny = pd.concat([c0,c1,c2,c3,c4,c5,c6],axis=0)\n",
    "\n",
    "df_canny.drop(labels=['Name'],inplace=True,axis=1)\n",
    "df_canny['Sentiment'] = df_canny['Sentiment'].map(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d1204ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_canny.drop(labels=['Sentiment'],axis=1)\n",
    "Y = df_canny[['Sentiment']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd641c20",
   "metadata": {},
   "source": [
    "## LDA - Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fbc83e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  45.5325232308792\n",
      "Recall:  34.663421610287074\n",
      "Precision:  34.690638534553905\n",
      "F1 score:  34.512107502555004\n",
      "Confusion Matrix: \n",
      "[[ 18  38  73]\n",
      " [ 58 145 256]\n",
      " [110 227 474]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.10      0.14      0.11       129\n",
      "     Neutral       0.35      0.32      0.33       459\n",
      "    Negative       0.59      0.58      0.59       811\n",
      "\n",
      "    accuracy                           0.46      1399\n",
      "   macro avg       0.35      0.35      0.35      1399\n",
      "weighted avg       0.47      0.46      0.46      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LDA_CN_model = LinearDiscriminantAnalysis()\n",
    "LDA_CN_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LDA_CN_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "LDA_CN_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6929a8",
   "metadata": {},
   "source": [
    "## Decision Tree - Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ea59a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  45.1036454610436\n",
      "Recall:  33.64218719898685\n",
      "Precision:  33.77424836450078\n",
      "F1 score:  33.63865906194199\n",
      "Confusion Matrix: \n",
      "[[ 14  38  77]\n",
      " [ 64 148 247]\n",
      " [ 92 250 469]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.08      0.11      0.09       129\n",
      "     Neutral       0.34      0.32      0.33       459\n",
      "    Negative       0.59      0.58      0.58       811\n",
      "\n",
      "    accuracy                           0.45      1399\n",
      "   macro avg       0.34      0.34      0.34      1399\n",
      "weighted avg       0.46      0.45      0.46      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT_CN_model = DecisionTreeClassifier(random_state=0)\n",
    "DT_CN_model.fit(X_train,y_train)\n",
    "y_pred = DT_CN_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "\n",
    "DT_CN_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1459f8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0f80289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  50.964974982130094\n",
      "Recall:  34.6470826260517\n",
      "Precision:  35.16679821693015\n",
      "F1 score:  34.04414344171744\n",
      "Confusion Matrix: \n",
      "[[  5  34  90]\n",
      " [ 12 135 312]\n",
      " [ 28 210 573]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.11      0.04      0.06       129\n",
      "     Neutral       0.36      0.29      0.32       459\n",
      "    Negative       0.59      0.71      0.64       811\n",
      "\n",
      "    accuracy                           0.51      1399\n",
      "   macro avg       0.35      0.35      0.34      1399\n",
      "weighted avg       0.47      0.51      0.48      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RFC_CN_model = RandomForestClassifier(n_estimators=8,random_state=0)\n",
    "RFC_CN_model.fit(X_train, y_train)\n",
    "y_pred = RFC_CN_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "\n",
    "RFC_CN_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f117210",
   "metadata": {},
   "source": [
    "## Multinomial NB - Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ddf36c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  46.89063616869193\n",
      "Recall:  33.541689742930885\n",
      "Precision:  33.598270226269946\n",
      "F1 score:  33.427107009591325\n",
      "Confusion Matrix: \n",
      "[[ 12  35  82]\n",
      " [ 56 126 277]\n",
      " [ 78 215 518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.08      0.09      0.09       129\n",
      "     Neutral       0.34      0.27      0.30       459\n",
      "    Negative       0.59      0.64      0.61       811\n",
      "\n",
      "    accuracy                           0.47      1399\n",
      "   macro avg       0.34      0.34      0.33      1399\n",
      "weighted avg       0.46      0.47      0.46      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB_CN_model = MultinomialNB()\n",
    "MNB_CN_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = MNB_CN_model.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "MNB_CN_y_pred = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b546d",
   "metadata": {},
   "source": [
    "# Majority voting for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6ab33372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  50.964974982130094\n",
      "Recall:  34.6470826260517\n",
      "Precision:  35.16679821693015\n",
      "F1 score:  34.04414344171744\n",
      "Confusion Matrix: \n",
      "[[  5  34  90]\n",
      " [ 12 135 312]\n",
      " [ 28 210 573]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.09      0.10      0.09       129\n",
      "     Neutral       0.37      0.24      0.29       459\n",
      "    Negative       0.59      0.69      0.64       811\n",
      "\n",
      "    accuracy                           0.49      1399\n",
      "   macro avg       0.35      0.35      0.34      1399\n",
      "weighted avg       0.47      0.49      0.47      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = LDA_CN_model\n",
    "model_2 = RFC_CN_model\n",
    "model_3 = MNB_CN_model\n",
    "\n",
    "final_model = VotingClassifier(estimators=[('lda_cn', model_1), ('dt_cn', model_2), ('mnb_cn', model_3)], voting='hard')\n",
    "final_model.fit(X_train, y_train)\n",
    "pred_final = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro')*100)\n",
    "print('F1 score: ',f1_score(y_test, y_pred, average='macro')*100)\n",
    "f1_img=f1_score(y_test, y_pred, average='macro')*100\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "target_names = ['Positive','Neutral', 'Negative']\n",
    "print(classification_report(y_test,pred_final,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b52aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(LDA_CN_y_pred)\n",
    "# print(DT_CN_y_pred)\n",
    "# print(MNB_CN_y_pred)\n",
    "\n",
    "# print(LR_TFIDF_y_pred)\n",
    "# print(SVM_TFIDF_y_pred)\n",
    "# print(ETC_TFIDF_y_pred)\n",
    "\n",
    "# print(len(LDA_CN_y_pred))\n",
    "# print(len(DT_CN_y_pred))\n",
    "# print(len(MNB_CN_y_pred))\n",
    "\n",
    "# print(len(LR_TFIDF_y_pred))\n",
    "# print(len(SVM_TFIDF_y_pred))\n",
    "# print(len(ETC_TFIDF_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c46eed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.6496928215287"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = (f1_img+f1_text)/2\n",
    "final "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
